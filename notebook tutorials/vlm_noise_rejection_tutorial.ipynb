{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# VLM Curation Tutorial\n",
        "\n",
        "This tutorial demonstrates how to use Vision-Language Models (VLM) to curate spike sorting results.\n",
        "\n",
        "## What is VLM Curation?\n",
        "\n",
        "VLM curation uses AI vision models (like GPT-4o or Claude) to classify units as \"Good\" or \"Bad\" based on visual features like waveforms, autocorrelograms, and spike locations. This provides an automated, AI-assisted approach to quality control.\n",
        "\n",
        "## Requirements\n",
        "\n",
        "- A `SortingAnalyzer` with computed extensions:\n",
        "  - `waveforms` (for waveform plots)\n",
        "  - `templates` (for multi-channel waveforms)\n",
        "  - `correlograms` (for autocorrelograms)\n",
        "  - `spike_locations` (for spike location plots)\n",
        "  - `spike_amplitudes` (for amplitude plots)\n",
        "  - `quality_metrics` (optional, for including quantitative metrics)\n",
        "\n",
        "- API key for your chosen VLM provider (OpenAI, Anthropic, or Google)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "_root_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
        "sys.path.insert(0, os.path.join(_root_dir, 'src'))\n",
        "\n",
        "import spikeinterface as si\n",
        "import numpy as np\n",
        "from spikeagent.app.tool.si_custom import create_unit_img_df\n",
        "from spikeagent.curation.vlm_curation import run_vlm_curation, plot_spike_images_with_result\n",
        "from spikeagent.app.tool.utils import get_model\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "print(\"Imports successful!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Create a SortingAnalyzer\n",
        "\n",
        "We'll create a synthetic `SortingAnalyzer` for demonstration. In practice, you would load your own recording and sorting.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Creating synthetic recording and sorting...\")\n",
        "recording, sorting = si.generate_ground_truth_recording(\n",
        "    durations=[10.0],\n",
        "    num_channels=16,\n",
        "    num_units=8,\n",
        "    sampling_frequency=30000.0,\n",
        "    noise_kwargs={'noise_levels': 5.0, 'strategy': 'on_the_fly'},\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "sorting_analyzer = si.create_sorting_analyzer(\n",
        "    sorting=sorting,\n",
        "    recording=recording,\n",
        "    format=\"memory\"\n",
        ")\n",
        "\n",
        "print(f\"Created sorting_analyzer with {len(sorting_analyzer.unit_ids)} units\")\n",
        "print(f\"Unit IDs: {list(sorting_analyzer.unit_ids)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Compute Required Extensions\n",
        "\n",
        "We need to compute all the extensions that VLM curation will use to generate images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Computing extensions...\")\n",
        "\n",
        "sorting_analyzer.compute(\"random_spikes\")\n",
        "sorting_analyzer.compute(\"noise_levels\")\n",
        "sorting_analyzer.compute(\"waveforms\", n_jobs=1)\n",
        "sorting_analyzer.compute(\"templates\")\n",
        "sorting_analyzer.compute(\"correlograms\", window_ms=100.0, bin_ms=1.0)\n",
        "sorting_analyzer.compute(\"spike_locations\", method=\"center_of_mass\")\n",
        "sorting_analyzer.compute(\"spike_amplitudes\")\n",
        "sorting_analyzer.compute(\"quality_metrics\")\n",
        "\n",
        "available_exts = [ext for ext in sorting_analyzer.get_computable_extensions() \n",
        "                  if sorting_analyzer.has_extension(ext)]\n",
        "print(f\"Computed extensions: {available_exts}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Create Image DataFrame\n",
        "\n",
        "The VLM needs images of each unit's features. We'll create a dataframe containing base64-encoded images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = [\"waveform_single\", \"autocorr\", \"spike_locations\"]\n",
        "\n",
        "print(f\"Creating image dataframe with features: {features}...\")\n",
        "import tempfile\n",
        "with tempfile.TemporaryDirectory() as tmpdir:\n",
        "    img_df = create_unit_img_df(\n",
        "        sorting_analyzer,\n",
        "        unit_ids=None,\n",
        "        features=features,\n",
        "        load_if_exists=False,\n",
        "        save_folder=tmpdir\n",
        "    )\n",
        "\n",
        "print(f\"Created image dataframe: {img_df.shape}\")\n",
        "print(f\"Units: {list(img_df.index)}\")\n",
        "print(f\"Features: {list(img_df.columns)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Run VLM Curation\n",
        "\n",
        "Now we'll use a Vision-Language Model to classify each unit as \"Good\" or \"Bad\".\n",
        "\n",
        "**Note:** This requires an API key. Set it in your environment or `.env` file:\n",
        "- `OPENAI_API_KEY` for GPT-4o\n",
        "- `ANTHROPIC_API_KEY` for Claude\n",
        "- `GOOGLE_API_KEY` for Gemini\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_name = \"gpt-4o\"\n",
        "model = get_model(model_name)\n",
        "\n",
        "print(f\"Initialized model: {model_name}\")\n",
        "\n",
        "print(\"\\nRunning VLM curation...\")\n",
        "print(\"This may take a few minutes depending on the number of units...\")\n",
        "\n",
        "results_df = run_vlm_curation(\n",
        "    model=model,\n",
        "    sorting_analyzer=sorting_analyzer,\n",
        "    img_df=img_df,\n",
        "    features=features,\n",
        "    good_ids=[],\n",
        "    bad_ids=[],\n",
        "    with_metrics=True,\n",
        "    unit_ids=None,\n",
        "    num_workers=10\n",
        ")\n",
        "\n",
        "print(f\"\\nVLM curation complete!\")\n",
        "print(f\"\\nResults summary:\")\n",
        "print(f\"Total units analyzed: {len(results_df)}\")\n",
        "print(f\"Good units: {len(results_df[results_df['final_classification'] == 'Good'])}\")\n",
        "print(f\"Bad units: {len(results_df[results_df['final_classification'] == 'Bad'])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: View Results\n",
        "\n",
        "Let's examine the results and see which units were classified as good or bad.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"VLM Curation Results:\")\n",
        "print(\"=\" * 60)\n",
        "print(results_df[['average_score', 'final_classification']].to_string())\n",
        "\n",
        "good_units = results_df[results_df['final_classification'] == 'Good'].index.tolist()\n",
        "bad_units = results_df[results_df['final_classification'] == 'Bad'].index.tolist()\n",
        "\n",
        "print(f\"\\nGood units: {good_units}\")\n",
        "print(f\"Bad units: {bad_units}\")\n",
        "\n",
        "print(\"\\nSample reasoning:\")\n",
        "for unit_id in list(sorting_analyzer.unit_ids)[:3]:\n",
        "    if unit_id in results_df.index:\n",
        "        print(f\"\\nUnit {unit_id}:\")\n",
        "        print(f\"Classification: {results_df.loc[unit_id, 'final_classification']}\")\n",
        "        print(f\"Score: {results_df.loc[unit_id, 'average_score']:.3f}\")\n",
        "        reasoning = results_df.loc[unit_id, 'combined_reasoning']\n",
        "        print(f\"Reasoning: {reasoning[:200]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Visualize Results\n",
        "\n",
        "Plot the units with their classification results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_spike_images_with_result(results_df, img_df, feature=\"waveform_single\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Apply Curation\n",
        "\n",
        "Finally, create a curated analyzer containing only the \"Good\" units.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if good_units:\n",
        "    curated_analyzer = sorting_analyzer.select_units(good_units)\n",
        "    print(f\"Created curated analyzer with {len(curated_analyzer.unit_ids)} units\")\n",
        "    print(f\"Original units: {len(sorting_analyzer.unit_ids)}\")\n",
        "    print(f\"Curated units: {len(curated_analyzer.unit_ids)}\")\n",
        "    print(f\"Removed: {len(sorting_analyzer.unit_ids) - len(curated_analyzer.unit_ids)} units\")\n",
        "else:\n",
        "    print(\"No 'Good' units found. Consider reviewing the results.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "agent",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
