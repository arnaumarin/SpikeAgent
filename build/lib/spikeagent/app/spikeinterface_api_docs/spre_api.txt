API for module: spikeinterface.preprocessing

Class: AlignSnippets
  Docstring:
    Abstract class representing several multichannel snippets.
  __init__(self, snippets, new_nbefore, new_nafter, mode='main_peak', interpolate=1, det_sign=0)

Class: AstypeRecording
  Docstring:
    The spikeinterface analog of numpy.astype
    
    Converts a recording to another dtype on the fly.
    
    For recording with an unsigned dtype, please use the `unsigned_to_signed` preprocessing function.
    
    Parameters
    ----------
    dtype : None | str | dtype, default: None
        dtype of the output recording. If None, takes dtype from input `recording`.
    recording : Recording
        The recording extractor to be converted.
    round : Bool | None, default: None
        If True, will round the values to the nearest integer using `numpy.round`.
        If None and dtype is an integer, will round floats to nearest integer.
    
    Returns
    -------
    astype_recording : AstypeRecording
        The converted recording extractor object
  __init__(self, recording, dtype=None, round: 'bool | None' = None)

Class: AverageAcrossDirectionRecording
  Docstring:
    Abstract class representing several a multichannel timeseries (or block of raw ephys traces).
    Internally handle list of RecordingSegment
  __init__(self, parent_recording: 'BaseRecording', direction: 'str' = 'y', dtype='float32')

Class: BandpassFilterRecording
  Docstring:
    Bandpass filter of a recording
    
    Parameters
    ----------
    recording : Recording
        The recording extractor to be re-referenced
    freq_min : float
        The highpass cutoff frequency in Hz
    freq_max : float
        The lowpass cutoff frequency in Hz
    margin_ms : float
        Margin in ms on border to avoid border effect
    dtype : dtype or None
        The dtype of the returned traces. If None, the dtype of the parent recording is used
    {}
    
    Returns
    -------
    filter_recording : BandpassFilterRecording
        The bandpass-filtered recording extractor object
  __init__(self, recording, freq_min=300.0, freq_max=6000.0, margin_ms=5.0, dtype=None, **filter_kwargs)

Class: BlankSaturationRecording
  Docstring:
    Find and remove parts of the signal with extereme values. Some arrays
    may produce these when amplifiers enter saturation, typically for
    short periods of time. To remove these artefacts, values below or above
    a threshold are set to the median signal value.
    The threshold is either be estimated automatically, using the lower and upper
    0.1 signal percentile with the largest deviation from the median, or specificed.
    Use this function with caution, as it may clip uncontaminated signals. A warning is
    printed if the data range suggests no artefacts.
    
    Parameters
    ----------
    recording : RecordingExtractor
        The recording extractor to be transformed
        Minimum value. If `None`, clipping is not performed on lower
        interval edge.
    abs_threshold : float or None, default: None
        The absolute value for considering that the signal is saturating
    quantile_threshold : float or None, default: None
        Tha value in [0, 1] used if abs_threshold is None to automatically set the
        abs_threshold given the data. Must be provided if abs_threshold is None
    direction : "upper" | "lower" | "both", default: "upper"
        Only values higher than the detection threshold are set to fill_value ("higher"),
        or only values lower than the detection threshold ("lower"), or both ("both")
    fill_value : float or None, default: None
        The value to write instead of the saturating signal. If None, then the value is
        automatically computed as the median signal value
    num_chunks_per_segment : int, default: 50
        The number of chunks per segments to consider to estimate the threshold/fill_values
    chunk_size : int, default: 500
        The chunk size to estimate the threshold/fill_values
    seed : int, default: 0
        The seed to select the random chunks
    
    Returns
    -------
    rescaled_traces : BlankSaturationRecording
        The filtered traces recording extractor object
  __init__(self, recording, abs_threshold=None, quantile_threshold=None, direction='upper', fill_value=None, num_chunks_per_segment=50, chunk_size=500, seed=0)

Class: CenterRecording
  Docstring:
    Centers traces from the given recording extractor by removing the median/mean of each channel.
    
    Parameters
    ----------
    recording : RecordingExtractor
        The recording extractor to be centered
    mode : "median" | "mean", default: "median"
        The method used to center the traces
    dtype : str or np.dtype, default: "float32"
        The dtype of the output traces
    **random_chunk_kwargs : Keyword arguments for `spikeinterface.core.get_random_data_chunk()` function
    
    Returns
    -------
    centered_traces : ScaleRecording
        The centered traces recording extractor object
  __init__(self, recording, mode='median', dtype='float32', **random_chunk_kwargs)

Class: ClipRecording
  Docstring:
    Limit the values of the data between a_min and a_max. Values exceeding the
    range will be set to the minimum or maximum, respectively.
    
    Parameters
    ----------
    recording : RecordingExtractor
        The recording extractor to be transformed
    a_min : float or None, default: None
        Minimum value. If `None`, clipping is not performed on lower
        interval edge.
    a_max : float or None, default: None
        Maximum value. If `None`, clipping is not performed on upper
        interval edge.
    
    Returns
    -------
    rescaled_traces : ClipTracesRecording
        The clipped traces recording extractor object
  __init__(self, recording, a_min=None, a_max=None)

Class: CommonReferenceRecording
  Docstring:
    Re-references the recording extractor traces. That is, the value of the traces are
    shifted so the there is a new zero (reference).
    
    The new reference can be estimated either by using a common median reference (CMR) or
    a common average reference (CAR).
    
    The new reference can be set three ways:
         * "global": the median/average of all channels is set as the new reference.
            In this case, the 'global' median/average is subtracted from all channels.
         * "single": In the simplest case, a single channel from the recording is set as the new reference.
            This channel is subtracted from all other channels. To use this option, the `ref_channel_ids` argument
            is used with a single channel id. Note that this option will zero out the reference channel.
            A collection of channels can also be used as the new reference. In this case, the median/average of the
            selected channels is subtracted from all other channels. To use this option, pass the group of channels as
            a list in `ref_channel_ids`.
         * "local": the median/average within an annulus is set as the new reference.
            The parameters of the annulus are specified using the `local_radius` argument. With this option, both
            channels which are too close and channels which are too far are excluded from the median/average. Note
            that setting the `local_radius` to (0, exclude_radius)  will yield a simple circular local region.
    
    
    Parameters
    ----------
    recording : RecordingExtractor
        The recording extractor to be re-referenced
    reference : "global" | "single" | "local", default: "global"
        If "global" the reference is the average or median across all the channels. To select a subset of channels,
        you can use the `ref_channel_ids` parameter.
        If "single", the reference is a single channel or a list of channels that need to be set with the `ref_channel_ids`.
        If "local", the reference is the set of channels within an annulus that must be set with the `local_radius` parameter.
    operator : "median" | "average", default: "median"
        If "median", a common median reference (CMR) is implemented (the median of
            the selected channels is removed for each timestamp).
        If "average", common average reference (CAR) is implemented (the mean of the selected channels is removed
            for each timestamp).
    groups : list or None, default: None
        List of lists containing the channel ids for splitting the reference. The CMR, CAR, or referencing with respect to
        single channels are applied group-wise. However, this is not applied for the local CAR.
        It is useful when dealing with different channel groups, e.g. multiple tetrodes.
    ref_channel_ids : list | str | int | None, default: None
        If "global" reference, a list of channels to be used as reference.
        If "single" reference, a list of one channel or a single channel id is expected.
        If "groups" is provided, then a list of channels to be applied to each group is expected.
    local_radius : tuple(int, int), default: (30, 55)
        Use in the local CAR implementation as the selecting annulus with the following format:
    
        `(exclude radius, include radius)`
    
        Where the exlude radius is the inner radius of the annulus and the include radius is the outer radius of the
        annulus. The exclude radius is used to exclude channels that are too close to the reference channel and the
        include radius delineates the outer boundary of the annulus whose role is to exclude channels
        that are too far away.
    
    dtype : None or dtype, default: None
        If None the parent dtype is kept.
    
    Returns
    -------
    referenced_recording : CommonReferenceRecording
        The re-referenced recording extractor object
  __init__(self, recording: 'BaseRecording', reference: "Literal['global', 'single', 'local']" = 'global', operator: "Literal['median', 'average']" = 'median', groups: 'list | None' = None, ref_channel_ids: 'list | str | int | None' = None, local_radius: 'tuple[float, float]' = (30.0, 55.0), dtype: 'str | np.dtype | None' = None)

Class: DecimateRecording
  Docstring:
    Decimate the recording extractor traces using array slicing
    
    Important: This uses simple array slicing for decimation rather than eg scipy.decimate.
    This might introduce aliasing, or skip across signal of interest.
    Consider  spikeinterface.preprocessing.ResampleRecording for safe resampling.
    
    Parameters
    ----------
    recording : Recording
        The recording extractor to be decimated. Each segment is decimated independently.
    decimation_factor : int
        Step between successive frames sampled from the parent recording.
        The same decimation factor is applied to all segments from the parent recording.
    decimation_offset : int, default: 0
        Index of first frame sampled from the parent recording.
        Expecting `decimation_offset` < `decimation_factor`, and `decimation_offset` < parent_recording.get_num_samples()
        to ensure that the decimated recording has at least one frame. Consider combining DecimateRecording
        with FrameSliceRecording for fine control on the recording start and end frames.
        The same decimation offset is applied to all segments from the parent recording.
    
    Returns
    -------
    decimate_recording: DecimateRecording
        The decimated recording extractor object. The full traces of the child recording segment
        correspond to the traces of the parent segment as follows:
            ```<decimated_traces> = <parent_traces>[<decimation_offset>::<decimation_factor>]```
  __init__(self, recording, decimation_factor, decimation_offset=0)

Class: DeepInterpolatedRecording
  Docstring:
    DeepInterpolatedRecording is a wrapper around a recording extractor that allows to apply a deepinterpolation model.
    
    For more information, see:
    Lecoq et al. (2021) Removing independent noise in systems neuroscience data using DeepInterpolation.
    Nature Methods. 18: 1401-1408. doi: 10.1038/s41592-021-01285-2.
    
    Parts of this code is adapted from https://github.com/AllenInstitute/deepinterpolation.
    
    Parameters
    ----------
    recording: BaseRecording
        The recording extractor to be deepinteprolated
    model_path: str
        Path to the deepinterpolation h5 model
    pre_frame: int
        Number of frames before the frame to be predicted
    post_frame: int
        Number of frames after the frame to be predicted
    pre_post_omission: int
        Number of frames to be omitted before and after the frame to be predicted
    batch_size: int
        Batch size to be used for the prediction
    predict_workers: int
        Number of workers to be used for the tensorflow `predict` function.
        Multiple workers can be used to speed up the prediction by pre-fetching the data.
    use_gpu: bool
        If True, the gpu will be used for the prediction
    disable_tf_logger: bool
        If True, the tensorflow logger will be disabled
    memory_gpu: int
        The amount of memory to be used by the gpu
    
    Returns
    -------
    recording: DeepInterpolatedRecording
        The deepinterpolated recording extractor object
  __init__(self, recording, model_path: 'str', pre_frame: 'int' = 30, post_frame: 'int' = 30, pre_post_omission: 'int' = 1, batch_size: 'int' = 128, use_gpu: 'bool' = True, predict_workers: 'int' = 1, disable_tf_logger: 'bool' = True, memory_gpu: 'Optional[int]' = None)

Class: DepthOrderRecording
  Docstring:
    Re-orders the recording (channel IDs, channel locations, and traces)
    
    Sorts channels lexicographically according to the dimensions in
    `dimensions`. See the documentation for `order_channels_by_depth`.
    
    Parameters
    ----------
    parent_recording : BaseRecording
        The recording to re-order.
    channel_ids : list/array or None
        If given, a subset of channels to order locations for
    dimensions : str or tuple, list, default: ("x", "y")
        If str, it needs to be "x", "y", "z".
        If tuple or list, it sorts the locations in two dimensions using lexsort.
        This approach is recommended since there is less ambiguity
    flip : bool, default: False
        If flip is False then the order is bottom first (starting from tip of the probe).
        If flip is True then the order is upper first.
  __init__(self, parent_recording, channel_ids=None, dimensions=('x', 'y'), flip=False)

Class: DirectionalDerivativeRecording
  Docstring:
    Abstract class representing several a multichannel timeseries (or block of raw ephys traces).
    Internally handle list of RecordingSegment
  __init__(self, recording: 'BaseRecording', direction: 'str' = 'y', order: 'int' = 1, edge_order: 'int' = 1, dtype='float32')

Class: FilterRecording
  Docstring:
    A generic filter class based on:
        For filter coefficient generation:
            * scipy.signal.iirfilter
        For filter application:
            * scipy.signal.filtfilt or scipy.signal.sosfiltfilt when direction = "forward-backward"
            * scipy.signal.lfilter or scipy.signal.sosfilt when direction = "forward" or "backward"
    
    BandpassFilterRecording is built on top of it.
    
    Parameters
    ----------
    recording : Recording
        The recording extractor to be re-referenced
    band : float or list, default: [300.0, 6000.0]
        If float, cutoff frequency in Hz for "highpass" filter type
        If list. band (low, high) in Hz for "bandpass" filter type
    btype : "bandpass" | "highpass", default: "bandpass"
        Type of the filter
    margin_ms : float, default: 5.0
        Margin in ms on border to avoid border effect
    coeff : array | None, default: None
        Filter coefficients in the filter_mode form.
    dtype : dtype or None, default: None
        The dtype of the returned traces. If None, the dtype of the parent recording is used
    add_reflect_padding : Bool, default False
        If True, uses a left and right margin during calculation.
    filter_order : order
        The order of the filter for `scipy.signal.iirfilter`
    filter_mode :  "sos" | "ba", default: "sos"
        Filter form of the filter coefficients for `scipy.signal.iirfilter`:
        - second-order sections ("sos")
        - numerator/denominator : ("ba")
    ftype : str, default: "butter"
        Filter type for `scipy.signal.iirfilter` e.g. "butter", "cheby1".
    direction : "forward" | "backward" | "forward-backward", default: "forward-backward"
        Direction of filtering:
        - "forward" - filter is applied to the timeseries in one direction, creating phase shifts
        - "backward" - the timeseries is reversed, the filter is applied and filtered timeseries reversed again. Creates phase shifts in the opposite direction to "forward"
        - "forward-backward" - Applies the filter in the forward and backward direction, resulting in zero-phase filtering. Note this doubles the effective filter order.
    
    Returns
    -------
    filter_recording : FilterRecording
        The filtered recording extractor object
  __init__(self, recording, band=[300.0, 6000.0], btype='bandpass', filter_order=5, ftype='butter', filter_mode='sos', margin_ms=5.0, add_reflect_padding=False, coeff=None, dtype=None, direction='forward-backward')

Class: GaussianFilterRecording
  Docstring:
    Class for performing a gaussian filtering/smoothing on a recording.
    
    This is done by a convolution with a Gaussian kernel, which acts as a lowpass-filter.
    A highpass-filter can be computed by subtracting the result of the convolution to
    the original signal.
    A bandpass-filter is obtained by substracting the signal smoothed with a narrow
    gaussian to the signal smoothed with a wider gaussian.
    
    Here, convolution is performed in the Fourier domain to accelerate the computation.
    
    Parameters
    ----------
    recording : BaseRecording
        The recording extractor to be filtered.
    freq_min : float or None
        The lower frequency cutoff for the bandpass filter.
        If None, the resulting object is a lowpass filter.
    freq_max : float or None
        The higher frequency cutoff for the bandpass filter.
        If None, the resulting object is a highpass filter.
    margin_sd : float, default: 5.0
        The number of standard deviation to take for margins.
    
    Returns
    -------
    gaussian_filtered_recording : GaussianFilterRecording
        The filtered recording extractor object.
  __init__(self, recording: 'BaseRecording', freq_min: 'float' = 300.0, freq_max: 'float' = 5000.0, margin_sd: 'float' = 5.0)

Class: HighpassFilterRecording
  Docstring:
    Highpass filter of a recording
    
    Parameters
    ----------
    recording : Recording
        The recording extractor to be re-referenced
    freq_min : float
        The highpass cutoff frequency in Hz
    margin_ms : float
        Margin in ms on border to avoid border effect
    dtype : dtype or None
        The dtype of the returned traces. If None, the dtype of the parent recording is used
    {}
    
    Returns
    -------
    filter_recording : HighpassFilterRecording
        The highpass-filtered recording extractor object
  __init__(self, recording, freq_min=300.0, margin_ms=5.0, dtype=None, **filter_kwargs)

Class: HighpassSpatialFilterRecording
  Docstring:
    Perform destriping with high-pass spatial filtering. Uses
    the kfilt() function of the International Brain Laboratory.
    
    Median average filtering, by removing the median of signal across
    channels, assumes noise is constant across all channels. However,
    noise have exhibit low-frequency changes across nearby channels.
    
    Alternative to median filtering across channels, in which the cut-band is
    extended from 0 to the 0.01 Nyquist corner frequency using butterworth filter.
    This allows removal of contaminating stripes that are not constant across channels.
    
    Performs filtering on the 0 axis (across channels), with optional
    padding (mirrored) and tapering (cosine taper) prior to filtering.
    Applies a butterworth filter on the 0-axis with tapering / padding.
    
    Parameters
    ----------
    recording : BaseRecording
        The parent recording
    n_channel_pad : int, default: 60
        Number of channels to pad prior to filtering.
        Channels are padded with mirroring.
        If None, no padding is applied
    n_channel_taper : int, default: 0
        Number of channels to perform cosine tapering on
        prior to filtering. If None and n_channel_pad is set,
        n_channel_taper will be set to the number of padded channels.
        Otherwise, the passed value will be used
    direction : "x" | "y" | "z", default: "y"
        The direction in which the spatial filter is applied
    apply_agc : bool, default: True
        It True, Automatic Gain Control is applied
    agc_window_length_s : float, default: 0.1
        Window in seconds to compute Hanning window for AGC
    highpass_butter_order : int, default: 3
        Order of spatial butterworth filter
    highpass_butter_wn : float, default: 0.01
        Critical frequency (with respect to Nyquist) of spatial butterworth filter
    dtype : dtype, default: None
        The dtype of the output traces. If None, the dtype is the same as the input traces
    
    Returns
    -------
    highpass_recording : HighpassSpatialFilterRecording
        The recording with highpass spatial filtered traces
    
    References
    ----------
    Details of the high-pass spatial filter function (written by Olivier Winter)
    used in the IBL pipeline can be found at:
    International Brain Laboratory et al. (2022). Spike sorting pipeline for the International Brain Laboratory.
    https://www.internationalbrainlab.com/repro-ephys
  __init__(self, recording, n_channel_pad=60, n_channel_taper=0, direction='y', apply_agc=True, agc_window_length_s=0.1, highpass_butter_order=3, highpass_butter_wn=0.01, dtype=None)

Class: InterpolateBadChannelsRecording
  Docstring:
    Interpolate the channel labeled as bad channels using linear interpolation.
    This is based on the distance (Gaussian kernel) from the bad channel,
    as determined from x,y channel coordinates.
    
    Details of the interpolation function (written by Olivier Winter) used in the IBL pipeline
    can be found at:
    
    International Brain Laboratory et al. (2022). Spike sorting pipeline for the
    International Brain Laboratory. https://www.internationalbrainlab.com/repro-ephys
    
    Parameters
    ----------
    recording : BaseRecording
        The parent recording
    bad_channel_ids : list or 1d np.array
        Channel ids of the bad channels to interpolate.
    sigma_um : float or None, default: None
        Distance between sequential channels in um. If None, will use
        the most common distance between y-axis channels
    p : float, default: 1.3
        Exponent of the Gaussian kernel. Determines rate of decay
        for distance weightings
    weights : np.array or None, default: None
        The weights to give to bad_channel_ids at interpolation.
        If None, weights are automatically computed
    
    Returns
    -------
    interpolated_recording : InterpolateBadChannelsRecording
        The recording object with interpolated bad channels
  __init__(self, recording, bad_channel_ids, sigma_um=None, p=1.3, weights=None)
  Method: check_inputs(self, recording, bad_channel_ids)
    Docstring:
      None

Class: NormalizeByQuantileRecording
  Docstring:
    Rescale the traces from the given recording extractor with a scalar
    and offset. First, the median and quantiles of the distribution are estimated.
    Then the distribution is rescaled and offset so that the scale is given by the
    distance between the quantiles (1st and 99th by default) is set to `scale`,
    and the median is set to the given median.
    
    Parameters
    ----------
    recording : RecordingExtractor
        The recording extractor to be transformed
    scale : float, default: 1.0
        Scale for the output distribution
    median : float, default: 0.0
        Median for the output distribution
    q1 : float, default: 0.01
        Lower quantile used for measuring the scale
    q2 : float, default: 0.99
        Upper quantile used for measuring the
    mode : "by_channel" | "pool_channel", default: "by_channel"
        If "by_channel" each channel is rescaled independently.
    dtype : str or np.dtype, default: "float32"
        The dtype of the output traces
    **random_chunk_kwargs : Keyword arguments for `spikeinterface.core.get_random_data_chunk()` function
    
    Returns
    -------
    rescaled_traces : NormalizeByQuantileRecording
        The rescaled traces recording extractor object
  __init__(self, recording, scale=1.0, median=0.0, q1=0.01, q2=0.99, mode='by_channel', dtype='float32', **random_chunk_kwargs)

Class: NotchFilterRecording
  Docstring:
    Parameters
    ----------
    recording : RecordingExtractor
        The recording extractor to be notch-filtered
    freq : int or float
        The target frequency in Hz of the notch filter
    q : int
        The quality factor of the notch filter
    dtype : None | dtype, default: None
        dtype of recording. If None, will take from `recording`
    margin_ms : float, default: 5.0
        Margin in ms on border to avoid border effect
    
    Returns
    -------
    filter_recording : NotchFilterRecording
        The notch-filtered recording extractor object
  __init__(self, recording, freq=3000, q=30, margin_ms=5.0, dtype=None)

Class: PhaseShiftRecording
  Docstring:
    This apply a phase shift to a recording to cancel the small sampling
    delay across for some recording system.
    
    This is particularly relevant for neuropixel recording.
    
    This code is inspired from from  IBL lib.
    https://github.com/int-brain-lab/ibllib/blob/master/ibllib/dsp/fourier.py
    and also the one from spikeglx
    https://billkarsh.github.io/SpikeGLX/help/dmx_vs_gbl/dmx_vs_gbl/
    
    Parameters
    ----------
    recording : Recording
        The recording. It need to have  "inter_sample_shift" in properties.
    margin_ms : float, default: 40.0
        Margin in ms for computation.
        40ms ensure a very small error when doing chunk processing
    inter_sample_shift : None or numpy array, default: None
        If "inter_sample_shift" is not in recording properties,
        we can externally provide one.
    dtype : None | str | dtype, default: None
        Dtype of input and output `recording` objects.
    
    
    Returns
    -------
    filter_recording : PhaseShiftRecording
        The phase shifted recording object
  __init__(self, recording, margin_ms=40.0, inter_sample_shift=None, dtype=None)

Class: RectifyRecording
  Docstring:
    Abstract class representing several a multichannel timeseries (or block of raw ephys traces).
    Internally handle list of RecordingSegment
  __init__(self, recording)

Class: RemoveArtifactsRecording
  Docstring:
    Removes stimulation artifacts from recording extractor traces. By default,
    artifact periods are zeroed-out (mode = "zeros"). This is only recommended
    for traces that are centered around zero (e.g. through a prior highpass
    filter); if this is not the case, linear and cubic interpolation modes are
    also available, controlled by the "mode" input argument.
    Note that several artifacts can be removed at once (potentially with
    distinct duration each), if labels are specified
    
    Parameters
    ----------
    recording : RecordingExtractor
        The recording extractor to remove artifacts from
    list_triggers : list of lists/arrays
        One list per segment of int with the stimulation trigger frames
    ms_before : float or None, default: 0.5
        Time interval in ms to remove before the trigger events.
        If None, then also ms_after must be None and a single sample is removed
    ms_after : float or None, default: 3.0
        Time interval in ms to remove after the trigger events.
        If None, then also ms_before must be None and a single sample is removed
    list_labels : list of lists/arrays or None
        One list per segment of labels with the stimulation labels for the given
        artifacts. labels should be strings, for JSON serialization.
        Required for "median" and "average" modes.
    mode : "zeros", "linear", "cubic", "average", "median", default: "zeros"
        Determines what artifacts are replaced by. Can be one of the following:
    
        - "zeros": Artifacts are replaced by zeros.
    
        - "median": The median over all artifacts is computed and subtracted for
            each occurence of an artifact
    
        - "average": The mean over all artifacts is computed and subtracted for each
            occurence of an artifact
    
        - "linear": Replacement are obtained through Linear interpolation between
           the trace before and after the artifact.
           If the trace starts or ends with an artifact period, the gap is filled
           with the closest available value before or after the artifact.
    
        - "cubic": Cubic spline interpolation between the trace before and after
           the artifact, referenced to evenly spaced fit points before and after
           the artifact. This is an option thatcan be helpful if there are
           significant LFP effects around the time of the artifact, but visual
           inspection of fit behaviour with your chosen settings is recommended.
           The spacing of fit points is controlled by "fit_sample_spacing", with
           greater spacing between points leading to a fit that is less sensitive
           to high frequency fluctuations but at the cost of a less smooth
           continuation of the trace.
           If the trace starts or ends with an artifact, the gap is filled with
           the closest available value before or after the artifact.
    fit_sample_spacing : float, default: 1.0
        Determines the spacing (in ms) of reference points for the cubic spline
        fit if mode = "cubic". Note : The actual fit samples are
        the median of the 5 data points around the time of each sample point to
        avoid excessive influence from hyper-local fluctuations.
    artifacts : dict or None, default: None
        If provided (when mode is "median" or "average") then it must be a dict with
        keys that are the labels of the artifacts, and values the artifacts themselves,
        on all channels (and thus bypassing ms_before and ms_after)
    sparsity : dict or None, default: None
        If provided (when mode is "median" or "average") then it must be a dict with
        keys that are the labels of the artifacts, and values that are boolean mask of
        the channels where the artifacts should be considered (for subtraction/scaling)
    scale_amplitude : False, default: False
        If true, then for mode "median" or "average" the amplitude of the template
        will be scaled in amplitude at each time occurence to minimize residuals
    time_jitter : float, default: 0
        If non 0, then for mode "median" or "average", a time jitter in ms
        can be allowed to minimize the residuals
    waveforms_kwargs : None
        Deprecated and ignored
    
    Returns
    -------
    removed_recording : RemoveArtifactsRecording
        The recording extractor after artifact removal
  __init__(self, recording, list_triggers, ms_before=0.5, ms_after=3.0, mode='zeros', fit_sample_spacing=1.0, list_labels=None, artifacts=None, sparsity=None, scale_amplitude=False, time_jitter=0, waveforms_kwargs=None)

Class: ResampleRecording
  Docstring:
    Resample the recording extractor traces.
    
    If the original sampling rate is multiple of the resample_rate, it will use
    the signal.decimate method from scipy. In other cases, it uses signal.resample. In the
    later case, the resulting signal can have issues on the edges, mainly on the
    rightmost.
    
    Parameters
    ----------
    recording : Recording
        The recording extractor to be re-referenced
    resample_rate : int
        The resampling frequency
    margin_ms : float, default: 100.0
        Margin in ms for computations, will be used to decrease edge effects.
    dtype : dtype or None, default: None
        The dtype of the returned traces. If None, the dtype of the parent recording is used.
    skip_checks : bool, default: False
        If True, checks on sampling frequencies and cutoff filter frequencies are skipped
    
    Returns
    -------
    resample_recording : ResampleRecording
        The resampled recording extractor object.
  __init__(self, recording, resample_rate, margin_ms=100.0, dtype=None, skip_checks=False)

Class: ScaleRecording
  Docstring:
    Scale traces from the given recording extractor with a scalar
    and offset. New traces = traces*scalar + offset.
    
    Parameters
    ----------
    recording : RecordingExtractor
        The recording extractor to be transformed
    gain : float or array
        Scalar for the traces of the recording extractor or array with scalars for each channel
    offset : float or array
        Offset for the traces of the recording extractor or array with offsets for each channel
    dtype : str or np.dtype, default: "float32"
        The dtype of the output traces
    
    Returns
    -------
    transform_traces : ScaleRecording
        The transformed traces recording extractor object
  __init__(self, recording, gain=1.0, offset=0.0, dtype='float32')

Class: SilencedPeriodsRecording
  Docstring:
    Silence user-defined periods from recording extractor traces. By default,
    periods are zeroed-out (mode = "zeros"). You can also fill the periods with noise.
    Note that both methods assume that traces that are centered around zero.
    If this is not the case, make sure you apply a filter or center function prior to
    silencing periods.
    
    Parameters
    ----------
    recording : RecordingExtractor
        The recording extractor to silance periods
    list_periods : list of lists/arrays
        One list per segment of tuples (start_frame, end_frame) to silence
    noise_levels : array
        Noise levels if already computed
    seed : int | None, default: None
        Random seed for `get_noise_levels` and `NoiseGeneratorRecording`.
        If none, `get_noise_levels` uses `seed=0` and `NoiseGeneratorRecording` generates a random seed using `numpy.random.default_rng`.
    mode : "zeros" | "noise, default: "zeros"
        Determines what periods are replaced by. Can be one of the following:
    
        - "zeros": Artifacts are replaced by zeros.
    
        - "noise": The periods are filled with a gaussion noise that has the
                   same variance that the one in the recordings, on a per channel
                   basis
    **random_chunk_kwargs : Keyword arguments for `spikeinterface.core.get_random_data_chunk()` function
    
    Returns
    -------
    silence_recording : SilencedPeriodsRecording
        The recording extractor after silencing some periods
  __init__(self, recording, list_periods, mode='zeros', noise_levels=None, seed=None, **random_chunk_kwargs)

Class: UnsignedToSignedRecording
  Docstring:
    Converts a recording with unsigned traces to a signed one.
    
    Parameters
    ----------
    recording : Recording
        The recording to be signed.
    bit_depth : int or None, default: None
        In case the bit depth of the ADC does not match that of the data type,
        it specifies the bit depth of the ADC to estimate the offset.
        For example, a `bit_depth` of 12 will correct for an offset of `2**11`
  __init__(self, recording, bit_depth=None)

Class: WhitenRecording
  Docstring:
    Whitens the recording extractor traces.
    
    Parameters
    ----------
    recording : RecordingExtractor
        The recording extractor to be whitened.
    dtype : None or dtype, default: None
        Datatype of the output recording (covariance matrix estimation
        and whitening are performed in float32).
        If None the the parent dtype is kept.
        For integer dtype a int_scale must be also given.
    mode : "global" | "local", default: "global"
        "global" use the entire covariance matrix to compute the W matrix
        "local" use local covariance (by radius) to compute the W matrix
    radius_um : None or float, default: None
        Used for mode = "local" to get the neighborhood
    apply_mean : bool, default: False
        Substract or not the mean matrix M before the dot product with W.
    int_scale : None or float, default: None
        Apply a scaling factor to fit the integer range.
        This is used when the dtype is an integer, so that the output is scaled.
        For example, a value of `int_scale=200` will scale the traces value to a standard deviation of 200.
    eps : float or None, default: None
        Small epsilon to regularize SVD.
        If None, eps is defaulted to 1e-8. If the data is float type and scaled down to very small values,
        then the eps is automatically set to a small fraction (1e-3) of the median of the squared data.
    W : 2d np.array or None, default: None
        Pre-computed whitening matrix
    M : 1d np.array or None, default: None
        Pre-computed means.
        M can be None when previously computed with apply_mean=False
    regularize : bool, default: False
        Boolean to decide if we want to regularize the covariance matrix, using a chosen method
        of sklearn, specified in regularize_kwargs. Default is GraphicalLassoCV
    regularize_kwargs : {'method' : 'GraphicalLassoCV'}
        Dictionary of the parameters that could be provided to the method of sklearn, if
        the covariance matrix needs to be regularized. Note that sklearn covariance methods
        that are implemented as functions, not classes, are not supported.
    **random_chunk_kwargs : Keyword arguments for `spikeinterface.core.get_random_data_chunk()` function
    
    Returns
    -------
    whitened_recording : WhitenRecording
        The whitened recording extractor
  __init__(self, recording, dtype=None, apply_mean=False, regularize=False, regularize_kwargs=None, mode='global', radius_um=100.0, int_scale=None, eps=None, W=None, M=None, **random_chunk_kwargs)

Class: ZScoreRecording
  Docstring:
    Centers traces from the given recording extractor by removing the median of each channel
    and dividing by the MAD.
    
    Parameters
    ----------
    recording : RecordingExtractor
        The recording extractor to be centered
    mode : "median+mad" | "mean+std", default: "median+mad"
        The mode to compute the zscore
    dtype : None or dtype
        If None the the parent dtype is kept.
        For integer dtype a int_scale must be also given.
    gain : None or np.array
        Pre-computed gain.
    offset : None or np.array
        Pre-computed offset
    int_scale : None or float
        Apply a scaling factor to fit the integer range.
        This is used when the dtype is an integer, so that the output is scaled.
        For example, a value of `int_scale=200` will scale the zscore value to a standard deviation of 200.
    **random_chunk_kwargs : Keyword arguments for `spikeinterface.core.get_random_data_chunk()` function
    
    Returns
    -------
    centered_traces : ScaleRecording
        The centered traces recording extractor object
  __init__(self, recording, mode='median+mad', gain=None, offset=None, int_scale=None, dtype='float32', **random_chunk_kwargs)

Class: ZeroChannelPaddedRecording
  Docstring:
    Abstract class representing several a multichannel timeseries (or block of raw ephys traces).
    Internally handle list of RecordingSegment
  __init__(self, recording: 'BaseRecording', num_channels: 'int', channel_mapping: 'Union[list, None]' = None)

Function: causal_filter(recording, direction='forward', band=[300.0, 6000.0], btype='bandpass', filter_order=5, ftype='butter', filter_mode='sos', margin_ms=5.0, add_reflect_padding=False, coeff=None, dtype=None)
  Docstring:
    Generic causal filter built on top of the filter function.
    
    Parameters
    ----------
    recording : Recording
        The recording extractor to be re-referenced
    direction : "forward" | "backward", default: "forward"
        Direction of causal filter. The "backward" option flips the traces in time before applying the filter
        and then flips them back.
    band : float or list, default: [300.0, 6000.0]
        If float, cutoff frequency in Hz for "highpass" filter type
        If list. band (low, high) in Hz for "bandpass" filter type
    btype : "bandpass" | "highpass", default: "bandpass"
        Type of the filter
    margin_ms : float, default: 5.0
        Margin in ms on border to avoid border effect
    coeff : array | None, default: None
        Filter coefficients in the filter_mode form.
    dtype : dtype or None, default: None
        The dtype of the returned traces. If None, the dtype of the parent recording is used
    add_reflect_padding : Bool, default False
        If True, uses a left and right margin during calculation.
    filter_order : order
        The order of the filter for `scipy.signal.iirfilter`
    filter_mode :  "sos" | "ba", default: "sos"
        Filter form of the filter coefficients for `scipy.signal.iirfilter`:
        - second-order sections ("sos")
        - numerator/denominator : ("ba")
    ftype : str, default: "butter"
        Filter type for `scipy.signal.iirfilter` e.g. "butter", "cheby1".
    
    Returns
    -------
    filter_recording : FilterRecording
        The causal-filtered recording extractor object

Function: compute_motion(recording: 'BaseRecording', preset: "Literal['dredge', 'medicine', 'dredge_fast', 'nonrigid_accurate', 'nonrigid_fast_and_accurate', 'rigid_fast', 'kilosort_like']" = 'dredge_fast', detect_kwargs: 'dict' = {}, select_kwargs: 'dict' = {}, localize_peaks_kwargs: 'dict' = {}, estimate_motion_kwargs: 'dict' = {}, output_motion_info: 'bool' = False, folder: 'str | Path | None' = None, overwrite: 'bool' = False, raise_error: 'bool' = True, **job_kwargs) -> 'dict'
  Docstring:
    Function to compute motion correction based on a preset e.g. 'dredge' or 'medicine'.
    
    This function has some intermediate steps that can be controlled one by one with parameters:
      * detect peaks
      * (optional) sub-sample peaks to speed up the localization
      * localize peaks
      * estimate the motion
    
    The recording must be preprocessed (filter and denoised at least), and we recommend to not use whitening before motion
    estimation. Since the motion interpolation requires a "float" recording, the recording is cast to float32 if necessary.
    
    Parameters for each step are handled as separate dictionaries.
    For more information please check the documentation of the following functions:
    
      * :py:func:`~spikeinterface.sortingcomponents.peak_detection.detect_peaks`
      * :py:func:`~spikeinterface.sortingcomponents.peak_selection.select_peaks`
      * :py:func:`~spikeinterface.sortingcomponents.peak_localization.localize_peaks`
      * :py:func:`~spikeinterface.sortingcomponents.motion.motion.estimate_motion`
    
    
      * dredge: Official Dredge preset
      * medicine: Medicine method: https://jazlab.github.io/medicine/
      * dredge_fast: Modified and faster Dredge preset
      * nonrigid_accurate: method by Paninski lab (monopolar_triangulation + decentralized)
      * nonrigid_fast_and_accurate: mixed methods by KS & Paninski lab (grid_convolution + decentralized)
      * rigid_fast: Rigid and not super accurate but fast. Use center of mass.
      * kilosort_like: Mimic the drift correction of kilosort (grid_convolution + iterative_template)
    
    Parameters
    ----------
    recording : RecordingExtractor
        The recording extractor to be transformed
    preset : str, default: "nonrigid_accurate"
        The preset name
    folder : Path str or None, default: None
        If not None then intermediate motion info are saved into a folder
    overwrite : bool, default: False
        If True and folder is given, overwrite the folder if it already exists
    detect_kwargs : dict
        Optional parameters to overwrite the ones in the preset for "detect" step.
    select_kwargs : dict
        If not None, optional parameters to overwrite the ones in the preset for "select" step.
        If None, the "select" step is skipped.
    localize_peaks_kwargs : dict
        Optional parameters to overwrite the ones in the preset for "localize" step.
    estimate_motion_kwargs : dict
        Optional parameters to overwrite the ones in the preset for "estimate_motion" step.
    interpolate_motion_kwargs : dict
        Optional parameters to overwrite the ones in the preset for "detect" step.
    output_motion_info : bool, default: False
        If True, then the function returns a `motion_info` dictionary that contains variables
        to check intermediate steps (motion_histogram, non_rigid_windows, pairwise_displacement)
        This dictionary is the same when reloaded from the folder.
    raise_error : bool, default: True
        If True, an error is raised if motion estimation fails
        If False, the process continues and the peaks and peak_locations are still returned in `motion_info`.
    
    Returns
    =======
    motion_info : dict
        A dictionary containing a motion objects, peaks, peak locations, run_times and the parameters used to compute these.

Function: compute_whitening_matrix(recording, mode, random_chunk_kwargs, apply_mean, radius_um=None, eps=None, regularize=False, regularize_kwargs=None)
  Docstring:
    Compute whitening matrix
    
    Parameters
    ----------
    recording : BaseRecording
        The recording object
    mode : str
        The mode to compute the whitening matrix.
    
        * "global": compute SVD using all channels
        * "local": compute SVD on local neighborhood (controlled by `radius_um`)
    
    random_chunk_kwargs : dict
        Keyword arguments for  get_random_data_chunks()
    apply_mean : bool
        If True, the mean is removed prior to computing the covariance
    radius_um : float or None, default: None
        Used for mode = "local" to get the neighborhood
    eps : float or None, default: None
        Small epsilon to regularize SVD. If None, the default is set to 1e-8, but if the data is float type and scaled
        down to very small values, eps is automatically set to a small fraction (1e-3) of the median of the squared data.
    regularize : bool, default: False
        Boolean to decide if we want to regularize the covariance matrix, using a chosen method
        of sklearn, specified in regularize_kwargs. Default is GraphicalLassoCV
    regularize_kwargs : {'method' : 'GraphicalLassoCV'}
        Dictionary of the parameters that could be provided to the method of sklearn, if
        the covariance matrix needs to be regularized.
    Returns
    -------
    W : 2D array
        The whitening matrix
    M : 2D array or None
        The "mean" matrix

Function: correct_lsb(recording, num_chunks_per_segment=20, chunk_size=10000, seed=None, verbose=False)
  Docstring:
    Estimates the LSB of the recording and divide traces by LSB
    to ensure LSB = 1. Medians are also subtracted to avoid rounding errors.
    
    Parameters
    ----------
    recording : RecordingExtractor
        The recording extractor to be LSB-corrected.
    num_chunks_per_segment : int, default: 20
        Number of chunks per segment for random chunk
    chunk_size : int, default: 10000
        Size of a chunk in number for random chunk
    seed : int or None, default: None
        Random seed for random chunk
    verbose : bool, default: False
        If True, estimate LSB value is printed
    
    Returns
    -------
    correct_lsb_recording : ScaleRecording
        The recording extractor with corrected LSB

Function: correct_motion(recording: 'BaseRecording', preset: "Literal['dredge', 'medicine', 'dredge_fast', 'nonrigid_accurate', 'nonrigid_fast_and_accurate', 'rigid_fast', 'kilosort_like']" = 'dredge_fast', folder: 'str | Path | None' = None, output_motion: 'bool' = False, output_motion_info: 'bool' = False, overwrite: 'bool' = False, detect_kwargs: 'dict' = {}, select_kwargs: 'dict' = {}, localize_peaks_kwargs: 'dict' = {}, estimate_motion_kwargs: 'dict' = {}, interpolate_motion_kwargs: 'dict' = {}, **job_kwargs)
  Docstring:
    High-level function that estimates the motion and interpolates the recording.
    
    This function has some intermediate steps that can be controlled one by one with parameters:
      * detect peaks
      * (optional) sub-sample peaks to speed up the localization
      * localize peaks
      * estimate the motion
      * create and return a `InterpolateMotionRecording` recording object
    
    Even if this function is convenient, we recommend to run all step separately for fine tuning.
    
    Optionally, this function can create a folder with files and figures ready to check.
    
    This function depends on several modular components of :py:mod:`spikeinterface.sortingcomponents`.
    
    If `select_kwargs` is None then all peak are used for localized.
    
    The recording must be preprocessed (filter and denoised at least), and we recommend to not use whitening before motion
    estimation. Since the motion interpolation requires a "float" recording, the recording is cast to float32 if necessary.
    
    Parameters for each step are handled as separate dictionaries.
    For more information please check the documentation of the following functions:
    
      * :py:func:`~spikeinterface.sortingcomponents.peak_detection.detect_peaks`
      * :py:func:`~spikeinterface.sortingcomponents.peak_selection.select_peaks`
      * :py:func:`~spikeinterface.sortingcomponents.peak_localization.localize_peaks`
      * :py:func:`~spikeinterface.sortingcomponents.motion.motion.estimate_motion`
      * :py:func:`~spikeinterface.sortingcomponents.motion.motion.interpolate_motion`
    
    
    Possible presets : 
      * dredge: Official Dredge preset
      * medicine: Medicine method: https://jazlab.github.io/medicine/
      * dredge_fast: Modified and faster Dredge preset
      * nonrigid_accurate: method by Paninski lab (monopolar_triangulation + decentralized)
      * nonrigid_fast_and_accurate: mixed methods by KS & Paninski lab (grid_convolution + decentralized)
      * rigid_fast: Rigid and not super accurate but fast. Use center of mass.
      * kilosort_like: Mimic the drift correction of kilosort (grid_convolution + iterative_template)
    
    
    Parameters
    ----------
    recording : RecordingExtractor
        The recording extractor to be transformed
    preset : str, default: "nonrigid_accurate"
        The preset name
    folder : Path str or None, default: None
        If not None then intermediate motion info are saved into a folder
    overwrite : bool, default: False
        If True and folder is given, overwrite the folder if it already exists
    detect_kwargs : dict
        Optional parameters to overwrite the ones in the preset for "detect" step.
    select_kwargs : dict
        If not None, optional parameters to overwrite the ones in the preset for "select" step.
        If None, the "select" step is skipped.
    localize_peaks_kwargs : dict
        Optional parameters to overwrite the ones in the preset for "localize" step.
    estimate_motion_kwargs : dict
        Optional parameters to overwrite the ones in the preset for "estimate_motion" step.
    interpolate_motion_kwargs : dict
        Optional parameters to overwrite the ones in the preset for "detect" step.
    output_motion_info : bool, default: False
        If True, then the function returns a `motion_info` dictionary that contains variables
        to check intermediate steps (motion_histogram, non_rigid_windows, pairwise_displacement)
        This dictionary is the same when reloaded from the folder.
    output_motion : bool, default: False
        It True, the function returns a `motion` object.
    
    **job_kwargs : keyword arguments for parallel processing:
            * chunk_duration or chunk_size or chunk_memory or total_memory
                - chunk_size : int
                    Number of samples per chunk
                - chunk_memory : str
                    Memory usage for each job (e.g. "100M", "1G", "500MiB", "2GiB")
                - total_memory : str
                    Total memory usage (e.g. "500M", "2G")
                - chunk_duration : str or float or None
                    Chunk duration in s if float or with units if str (e.g. "1s", "500ms")
            * n_jobs : int | float
                Number of jobs to use. With -1 the number of jobs is the same as number of cores.
                Using a float between 0 and 1 will use that fraction of the total cores.
            * progress_bar : bool
                If True, a progress bar is printed
            * mp_context : "fork" | "spawn" | None, default: None
                Context for multiprocessing. It can be None, "fork" or "spawn".
                Note that "fork" is only safely available on LINUX systems
    
    
    Returns
    -------
    recording_corrected : Recording
        The motion corrected recording
    motion : Motion
        Optional output if `output_motion=True`.
    motion_info : dict
        Optional output if `output_motion_info=True`. This dict contains several variable for
        for plotting. See `plot_motion_info()`

Function: detect_bad_channels(recording: 'BaseRecording', method: 'str' = 'coherence+psd', std_mad_threshold: 'float' = 5, psd_hf_threshold: 'float' = 0.02, dead_channel_threshold: 'float' = -0.5, noisy_channel_threshold: 'float' = 1.0, outside_channel_threshold: 'float' = -0.75, outside_channels_location: "Literal['top', 'bottom', 'both']" = 'top', n_neighbors: 'int' = 11, nyquist_threshold: 'float' = 0.8, direction: "Literal['x', 'y', 'z']" = 'y', chunk_duration_s: 'float' = 0.3, num_random_chunks: 'int' = 100, welch_window_ms: 'float' = 10.0, highpass_filter_cutoff: 'float' = 300, neighborhood_r2_threshold: 'float' = 0.9, neighborhood_r2_radius_um: 'float' = 30.0, seed: 'int | None' = None)
  Docstring:
    Perform bad channel detection.
    The recording is assumed to be filtered. If not, a highpass filter is applied on the fly.
    
    Different methods are implemented:
    
    * std : threhshold on channel standard deviations
        If the standard deviation of a channel is greater than `std_mad_threshold` times the median of all
        channels standard deviations, the channel is flagged as noisy
    * mad : same as std, but using median absolute deviations instead
    * coeherence+psd : method developed by the International Brain Laboratory that detects bad channels of three types:
        * Dead channels are those with low similarity to the surrounding channels (n=`n_neighbors` median)
        * Noise channels are those with power at >80% Nyquist above the psd_hf_threshold (default 0.02 uV^2 / Hz)
          and a high coherence with "far away" channels"
        * Out of brain channels are contigious regions of channels dissimilar to the median of all channels
          at the top end of the probe (i.e. large channel number)
    * neighborhood_r2
        A method tuned for LFP use-cases, where channels should be highly correlated with their spatial
        neighbors. This method estimates the correlation of each channel with the median of its spatial
        neighbors, and considers channels bad when this correlation is too small.
    
    Parameters
    ----------
    recording : BaseRecording
        The recording for which bad channels are detected
    method : "coeherence+psd" | "std" | "mad" | "neighborhood_r2", default: "coeherence+psd"
        The method to be used for bad channel detection
    std_mad_threshold : float, default: 5
        The standard deviation/mad multiplier threshold
    psd_hf_threshold : float, default: 0.02
        For coherence+psd - an absolute threshold (uV^2/Hz) used as a cutoff for noise channels.
        Channels with average power at >80% Nyquist larger than this threshold
        will be labeled as noise
    dead_channel_threshold : float, default: -0.5
        For coherence+psd - threshold for channel coherence below which channels are labeled as dead
    noisy_channel_threshold : float, default: 1
        Threshold for channel coherence above which channels are labeled as noisy (together with psd condition)
    outside_channel_threshold : float, default: -0.75
        For coherence+psd - threshold for channel coherence above which channels at the edge of the recording are marked as outside
        of the brain
    outside_channels_location : "top" | "bottom" | "both", default: "top"
        For coherence+psd - location of the outside channels. If "top", only the channels at the top of the probe can be
        marked as outside channels. If "bottom", only the channels at the bottom of the probe can be
        marked as outside channels. If "both", both the channels at the top and bottom of the probe can be
        marked as outside channels
    n_neighbors : int, default: 11
        For coeherence+psd - number of channel neighbors to compute median filter (needs to be odd)
    nyquist_threshold : float, default: 0.8
        For coherence+psd - frequency with respect to Nyquist (Fn=1) above which the mean of the PSD is calculated and compared
        with psd_hf_threshold
    direction : "x" | "y" | "z", default: "y"
        For coherence+psd - the depth dimension
    highpass_filter_cutoff : float, default: 300
        If the recording is not filtered, the cutoff frequency of the highpass filter
    chunk_duration_s : float, default: 0.5
        Duration of each chunk
    num_random_chunks : int, default: 100
        Number of random chunks
        Having many chunks is important for reproducibility.
    welch_window_ms : float, default: 10
        Window size for the scipy.signal.welch that will be converted to nperseg
    neighborhood_r2_threshold : float, default: 0.95
        R^2 threshold for the neighborhood_r2 method.
    neighborhood_r2_radius_um : float, default: 30
        Spatial radius below which two channels are considered neighbors in the neighborhood_r2 method.
    seed : int or None, default: None
        The random seed to extract chunks
    
    Returns
    -------
    bad_channel_ids : np.array
        The identified bad channel ids
    channel_labels : np.array of str
        Channels labels depending on the method:
          * (coeherence+psd) good/dead/noise/out
          * (std, mad) good/noise
    
    Examples
    --------
    
    >>> import spikeinterface.preprocessing as spre
    >>> bad_channel_ids, channel_labels = spre.detect_bad_channels(recording, method="coherence+psd")
    >>> # remove bad channels
    >>> recording_clean = recording.remove_channels(bad_channel_ids)
    
    Notes
    -----
    For details refer to:
    International Brain Laboratory et al. (2022). Spike sorting pipeline for the International Brain Laboratory.
    https://www.internationalbrainlab.com/repro-ephys

Function: get_motion_parameters_preset(preset)
  Docstring:
    Get the parameters tree for a given preset for motion correction.
    
    Parameters
    ----------
    preset : str, default: None
        The preset name. See available presets using `spikeinterface.preprocessing.get_motion_presets()`.

Function: get_motion_presets()
  Docstring:
    None

Function: get_spatial_interpolation_kernel(source_location, target_location, method='kriging', sigma_um=20.0, p=1, num_closest=4, sparse_thresh=None, dtype='float32', force_extrapolate=False)
  Docstring:
    Compute the spatial kernel for linear spatial interpolation.
    
    This is used for interpolation of bad channels or to correct the drift
    by interpolating between contacts.
    
    For reference, here is a simple overview on spatial interpolation:
    https://www.aspexit.com/spatial-data-interpolation-tin-idw-kriging-block-kriging-co-kriging-what-are-the-differences/
    
    Parameters
    ----------
    source_location: array shape (m, 2)
        The recording extractor to be transformed
    target_location: array shape (n, 2)
        Scale for the output distribution
    method: "kriging" | "idw" | "nearest", default: "kriging"
        Choice of the method
            "kriging" : the same one used in kilosort
            "idw" : inverse  distance weithed
            "nearest" : use neareast channel
    sigma_um : float or list, default: 20.0
        Used in the "kriging" formula. When list, it needs to have 2 elements (for the x and y directions).
    p: int, default: 1
        Used in the "kriging" formula
    sparse_thresh: None or float, default: None
        If not None for "kriging" force small value to be zeros to get a sparse matrix.
    num_closest: int, default: 4
        Used for "idw"
    force_extrapolate: bool, default: False
        How to handle when target location are outside source location.
        When False :  no extrapolation all target location outside are set to zero.
        When True : extrapolation done with the formula of the method.
                    In that case the sum of the kernel is not force to be 1.
    
    Returns
    -------
    interpolation_kernel: array (m, n)

Function: load_motion_info(folder)
  Docstring:
    None

Function: save_motion_info(motion_info, folder, overwrite=False)
  Docstring:
    None

Function: scale_to_uV(recording: 'BasePreprocessor') -> 'BasePreprocessor'
  Docstring:
    Scale raw traces to microvolts (V).
    
    This preprocessor uses the channel-specific gain and offset information
    stored in the recording extractor to convert the raw traces to V units.
    
    Parameters
    ----------
    recording : BaseRecording
        The recording extractor to be scaled. The recording extractor must
        have gains and offsets otherwise an error will be raised.
    
    Raises
    ------
    AssertionError
        If the recording extractor does not have scaleable traces.

Function: train_deepinterpolation(recordings: 'BaseRecording | list[BaseRecording]', model_folder: 'str | Path', model_name: 'str', desired_shape: 'tuple[int, int]', train_start_s: 'Optional[float]' = None, train_end_s: 'Optional[float]' = None, train_duration_s: 'Optional[float]' = None, test_start_s: 'Optional[float]' = None, test_end_s: 'Optional[float]' = None, test_duration_s: 'Optional[float]' = None, test_recordings: 'Optional[BaseRecording | list[BaseRecording]]' = None, pre_frame: 'int' = 30, post_frame: 'int' = 30, pre_post_omission: 'int' = 1, existing_model_path: 'Optional[str | Path]' = None, verbose: 'bool' = True, nb_gpus: 'int' = 1, steps_per_epoch: 'int' = 10, period_save: 'int' = 100, apply_learning_decay: 'int' = 0, nb_times_through_data: 'int' = 1, learning_rate: 'float' = 0.0001, loss: 'str' = 'mean_squared_error', nb_workers: 'int' = -1, caching_validation: 'bool' = False, run_uid: 'str' = 'si', network: 'Callable | None' = None, use_gpu: 'bool' = True, disable_tf_logger: 'bool' = True, memory_gpu: 'Optional[int]' = None)
  Docstring:
    Train a deepinterpolation model from a recording extractor.
    
    Parameters
    ----------
    recordings : BaseRecording | list[BaseRecording]
        The recording(s) to be deepinteprolated. If a list is given, the recordings are concatenated
        and samples at the border of the recordings are omitted.
    model_folder : str | Path
        Path to the folder where the model will be saved
    model_name : str
        Name of the model to be used
    train_start_s : float or None, default: None
        Start time of the training in seconds. If None, the training starts at the beginning of the recording
    train_end_s : float or None, default: None
        End time of the training in seconds. If None, the training ends at the end of the recording
    train_duration_s : float, default: None
        Duration of the training in seconds. If None, the entire [train_start_s, train_end_s] is used for training
    test_start_s : float or None, default: None
        Start time of the testing in seconds. If None, the testing starts at the beginning of the recording
    test_end_s : float or None, default: None
        End time of the testing in seconds. If None, the testing ends at the end of the recording
    test_duration_s : float or None, default: None
        Duration of the testing in seconds, If None, the entire [test_start_s, test_end_s] is used for testing (not recommended)
    test_recordings : BaseRecording | list[BaseRecording] | None, default: None
        The recording(s) used for testing. If None, the training recording (or recordings) is used for testing
    desired_shape : tuple
        Shape of the input to the network
    pre_frame : int
        Number of frames before the frame to be predicted
    post_frame : int
        Number of frames after the frame to be predicted
    pre_post_omission : int
        Number of frames to be omitted before and after the frame to be predicted
    existing_model_path : str | Path | None, default: None
        Path to an existing model to be used for transfer learning
    verbose : bool, default: True
        Whether to print the progress of the training
    steps_per_epoch : int, default: 10
        Number of steps per epoch
    period_save : int, default: 100
        Period of saving the model
    apply_learning_decay : int, default: 0
        Whether to use a learning scheduler during training
    nb_times_through_data : int, default: 1
        Number of times the data is repeated during training
    learning_rate : float, default: 0.0001
        Learning rate
    loss : str, default: "mean_squared_error"
        Loss function to be used
    nb_workers : int, default: -1
        Number of workers to be used for the training
    caching_validation : bool, default: False
        Whether to cache the validation data
    run_uid : str, default: "si"
        Unique identifier for the training
    network : Callable or None, default: None
        Name deepinterpolation network to use. If None, the "unet_single_ephys_1024" network is used.
        The network should be a callable that takes a dictionary as input and returns a deepinterpolation network.
        See deepinterpolation.network_collection for examples.
    use_gpu : bool, default: True
        Whether to use GPU
    disable_tf_logger : bool, default: True
        Whether to disable the tensorflow logger
    memory_gpu : int, default: None
        Amount of memory to be used by the GPU
    
    Returns
    -------
    model_path : Path
        Path to the model
