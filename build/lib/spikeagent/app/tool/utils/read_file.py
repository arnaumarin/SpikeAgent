import os
import time
import numpy as np
from .intanutils import *
import spikeinterface.extractors as se

def read_rhd_file(filename):
    """Reads Intan Technologies RHD2000 data file generated by evaluation board GUI.
    
    Data are returned in a dictionary, for future extensibility.
    """

    tic = time.time()
    fid = open(filename, 'rb')
    filesize = os.path.getsize(filename)

    header = read_header(fid)

    print('Found {} amplifier channel{}.'.format(header['num_amplifier_channels'], plural(header['num_amplifier_channels'])))
    print('Found {} auxiliary input channel{}.'.format(header['num_aux_input_channels'], plural(header['num_aux_input_channels'])))
    print('Found {} supply voltage channel{}.'.format(header['num_supply_voltage_channels'], plural(header['num_supply_voltage_channels'])))
    print('Found {} board ADC channel{}.'.format(header['num_board_adc_channels'], plural(header['num_board_adc_channels'])))
    print('Found {} board digital input channel{}.'.format(header['num_board_dig_in_channels'], plural(header['num_board_dig_in_channels'])))
    print('Found {} board digital output channel{}.'.format(header['num_board_dig_out_channels'], plural(header['num_board_dig_out_channels'])))
    print('Found {} temperature sensors channel{}.'.format(header['num_temp_sensor_channels'], plural(header['num_temp_sensor_channels'])))
    print('')

    # Determine how many samples the data file contains.
    bytes_per_block = get_bytes_per_data_block(header)

    # How many data blocks remain in this file?
    data_present = False
    bytes_remaining = filesize - fid.tell()
    if bytes_remaining > 0:
        data_present = True

    if bytes_remaining % bytes_per_block != 0:
        raise Exception('Something is wrong with file size : should have a whole number of data blocks')

    num_data_blocks = int(bytes_remaining / bytes_per_block)

    num_amplifier_samples = header['num_samples_per_data_block'] * num_data_blocks
    num_aux_input_samples = int((header['num_samples_per_data_block'] / 4) * num_data_blocks)
    num_supply_voltage_samples = 1 * num_data_blocks
    num_board_adc_samples = header['num_samples_per_data_block'] * num_data_blocks
    num_board_dig_in_samples = header['num_samples_per_data_block'] * num_data_blocks
    num_board_dig_out_samples = header['num_samples_per_data_block'] * num_data_blocks

    record_time = num_amplifier_samples / header['sample_rate']

    if data_present:
        print('File contains {:0.3f} seconds of data.  Amplifiers were sampled at {:0.2f} kS/s.'.format(record_time, header['sample_rate'] / 1000))
    else:
        print('Header file contains no data.  Amplifiers were sampled at {:0.2f} kS/s.'.format(header['sample_rate'] / 1000))

    if data_present:
        # Pre-allocate memory for data.
        print('')
        print('Allocating memory for data...')

        data = {}
        if (header['version']['major'] == 1 and header['version']['minor'] >= 2) or (header['version']['major'] > 1):
            data['t_amplifier'] = np.zeros(num_amplifier_samples, dtype=np.int64)
        else:
            data['t_amplifier'] = np.zeros(num_amplifier_samples, dtype=np.uint)

        data['amplifier_data'] = np.zeros([header['num_amplifier_channels'], num_amplifier_samples], dtype=np.uint)
        data['aux_input_data'] = np.zeros([header['num_aux_input_channels'], num_aux_input_samples], dtype=np.uint)
        data['supply_voltage_data'] = np.zeros([header['num_supply_voltage_channels'], num_supply_voltage_samples], dtype=np.uint)
        data['temp_sensor_data'] = np.zeros([header['num_temp_sensor_channels'], num_supply_voltage_samples], dtype=np.uint)
        data['board_adc_data'] = np.zeros([header['num_board_adc_channels'], num_board_adc_samples], dtype=np.uint)
        
        # by default, this script interprets digital events (digital inputs and outputs) as booleans
        # if unsigned int values are preferred(0 for False, 1 for True), replace the 'dtype=np.bool' argument with 'dtype=np.uint' as shown
        # the commented line below illustrates this for digital input data; the same can be done for digital out
        
        #data['board_dig_in_data'] = np.zeros([header['num_board_dig_in_channels'], num_board_dig_in_samples], dtype=np.uint)
        data['board_dig_in_data'] = np.zeros([header['num_board_dig_in_channels'], num_board_dig_in_samples], dtype=np.bool_)
        data['board_dig_in_raw'] = np.zeros(num_board_dig_in_samples, dtype=np.uint)
        
        data['board_dig_out_data'] = np.zeros([header['num_board_dig_out_channels'], num_board_dig_out_samples], dtype=np.bool_)
        data['board_dig_out_raw'] = np.zeros(num_board_dig_out_samples, dtype=np.uint)

        # Read sampled data from file.
        print('Reading data from file...')

        # Initialize indices used in looping
        indices = {}
        indices['amplifier'] = 0
        indices['aux_input'] = 0
        indices['supply_voltage'] = 0
        indices['board_adc'] = 0
        indices['board_dig_in'] = 0
        indices['board_dig_out'] = 0

        print_increment = 10
        percent_done = print_increment
        for i in range(num_data_blocks):
            read_one_data_block(data, header, indices, fid)

            # Increment indices
            indices['amplifier'] += header['num_samples_per_data_block']
            indices['aux_input'] += int(header['num_samples_per_data_block'] / 4)
            indices['supply_voltage'] += 1
            indices['board_adc'] += header['num_samples_per_data_block']
            indices['board_dig_in'] += header['num_samples_per_data_block']
            indices['board_dig_out'] += header['num_samples_per_data_block']            

            fraction_done = 100 * (1.0 * i / num_data_blocks)
            if fraction_done >= percent_done:
                print('{}% done...'.format(percent_done))
                percent_done = percent_done + print_increment

        # Make sure we have read exactly the right amount of data.
        bytes_remaining = filesize - fid.tell()
        if bytes_remaining != 0: raise Exception('Error: End of file not reached.')



    # Close data file.
    fid.close()

    if (data_present):
        print('Parsing data...')

        # Extract digital input channels to separate variables.
        for i in range(header['num_board_dig_in_channels']):
            data['board_dig_in_data'][i, :] = np.not_equal(np.bitwise_and(data['board_dig_in_raw'], (1 << header['board_dig_in_channels'][i]['native_order'])), 0)

        # Extract digital output channels to separate variables.
        for i in range(header['num_board_dig_out_channels']):
            data['board_dig_out_data'][i, :] = np.not_equal(np.bitwise_and(data['board_dig_out_raw'], (1 << header['board_dig_out_channels'][i]['native_order'])), 0)

        # Scale voltage levels appropriately.
        data['amplifier_data'] = np.multiply(0.195, (data['amplifier_data'].astype(np.int32) - 32768))      # units = microvolts
        data['aux_input_data'] = np.multiply(37.4e-6, data['aux_input_data'])               # units = volts
        data['supply_voltage_data'] = np.multiply(74.8e-6, data['supply_voltage_data'])     # units = volts
        if header['eval_board_mode'] == 1:
            data['board_adc_data'] = np.multiply(152.59e-6, (data['board_adc_data'].astype(np.int32) - 32768)) # units = volts
        elif header['eval_board_mode'] == 13:
            data['board_adc_data'] = np.multiply(312.5e-6, (data['board_adc_data'].astype(np.int32) - 32768)) # units = volts
        else:
            data['board_adc_data'] = np.multiply(50.354e-6, data['board_adc_data'])           # units = volts
        data['temp_sensor_data'] = np.multiply(0.01, data['temp_sensor_data'])               # units = deg C

        # Check for gaps in timestamps.
        num_gaps = np.sum(np.not_equal(data['t_amplifier'][1:]-data['t_amplifier'][:-1], 1))
        if num_gaps == 0:
            print('No missing timestamps in data.')
        else:
            print('Warning: {0} gaps in timestamp data found.  Time scale will not be uniform!'.format(num_gaps))

        # Scale time steps (units = seconds).
        data['t_amplifier'] = data['t_amplifier'] / header['sample_rate']
        data['t_aux_input'] = data['t_amplifier'][range(0, len(data['t_amplifier']), 4)]
        data['t_supply_voltage'] = data['t_amplifier'][range(0, len(data['t_amplifier']), header['num_samples_per_data_block'])]
        data['t_board_adc'] = data['t_amplifier']
        data['t_dig'] = data['t_amplifier']
        data['t_temp_sensor'] = data['t_supply_voltage']

        # If the software notch filter was selected during the recording, apply the
        # same notch filter to amplifier data here.
        if header['notch_filter_frequency'] > 0 and header['version']['major'] < 3:
            print('Applying notch filter...')

            print_increment = 10
            percent_done = print_increment
            for i in range(header['num_amplifier_channels']):
                data['amplifier_data'][i,:] = notch_filter(data['amplifier_data'][i,:], header['sample_rate'], header['notch_filter_frequency'], 10)

                fraction_done = 100 * (i / header['num_amplifier_channels'])
                if fraction_done >= percent_done:
                    print('{}% done...'.format(percent_done))
                    percent_done += print_increment
    else:
        data = []

    # Move variables to result struct.
    result = data_to_result(header, data, data_present)

    print('Done!  Elapsed time: {0:0.1f} seconds'.format(time.time() - tic))
    return result

# --- NEW WRAPPER FUNCTION ---
def read_rhd_to_recording(folder_path: str) -> se.NumpyRecording:
    """
    Scans a directory for .rhd files, reads and concatenates them, and returns
    a single SpikeInterface NumpyRecording object.

    This function is a wrapper around the custom 'read_rhd_file' utility.

    Parameters:
        - folder_path: The path to the directory containing .rhd files.

    Returns:
        A SpikeInterface NumpyRecording object.
    """
    print(f"Scanning for .rhd files in: {folder_path}")
    traces_list = []
    sr = None

    # Find all .rhd files recursively
    rhd_files = []
    for dirpath, _, filenames in os.walk(folder_path):
        for fname in sorted(filenames):
            if fname.endswith(".rhd"):
                rhd_files.append(os.path.join(dirpath, fname))

    if not rhd_files:
        raise FileNotFoundError(f"No .rhd files found in {folder_path}")

    print(f"Found {len(rhd_files)} file(s). Loading and concatenating...")
    for filepath in rhd_files:
        # Use your custom reader
        raw = read_rhd_file(filepath)

        # Get sampling frequency (and ensure it's consistent)
        current_sr = raw['frequency_parameters']['amplifier_sample_rate']
        if sr is None:
            sr = current_sr
        elif sr != current_sr:
            raise ValueError("All .rhd files must have the same sampling rate.")

        # Extract and transpose traces for correct shape (samples, channels)
        traces = raw['amplifier_data'].T
        traces_list.append(traces)

    # Stack all recordings into one contiguous numpy array
    all_traces = np.vstack(traces_list)
    
    # Create the SpikeInterface recording object
    # This directly returns the object without needing extra steps in the agent's code
    recording = se.NumpyRecording(traces_list=[all_traces], sampling_frequency=sr)
    
    print("Successfully created a SpikeInterface recording object.")
    return recording


from pathlib import Path
import json
import h5py
import numpy as np
from typing import Optional
from probeinterface import Probe
from spikeinterface.extractors import read_binary
from spikeinterface.preprocessing import scale


def read_nwb_to_recording(
    folder_path: str,
    fs: float = 24414.0625,
    chunk_samp: int = 200_000,
    dset_path: str = "/acquisition/timeseries/broadband/data",
    elec_map_path: str = "/general/extracellular_ephys/electrode_map",
    out_dir: Optional[str] = None,
    overwrite: bool = True,
):
    """
    Convert all .nwb files under `raw_dir` to interleaved float32 .bin files by streaming,
    and save channel locations (.npy) and a small metadata .json (includes fs).

    Parameters
    ----------
    raw_dir : str
        Directory containing .nwb files.
    dset_path : str
        HDF5 path to the broadband data; expected shape (time, channels).
    elec_map_path : str
        HDF5 path to the electrode map (channel locations). If missing, it's skipped.
    fs : float
        Sampling rate (Hz) to record in metadata json.
    chunk_samp : int
        Number of time samples per chunk to stream from disk (memory control).
    out_dir : Optional[str]
        If provided, write outputs here; otherwise, next to each .nwb file.
    overwrite : bool
        Whether to overwrite existing outputs.

    Outputs per NWB
    ---------------
    - <stem>.bin                  (float32, shape: time x channels, interleaved by time)
    - <stem>_channel_locations.npy (if available)
    - <stem>.json                 (metadata: fs, n_samples, n_channels, dtype, paths, conversion)
    """
    raw_dir = Path(folder_path)
    if out_dir is not None:
        out_dir = Path(out_dir)
        out_dir.mkdir(parents=True, exist_ok=True)

    nwb_files = sorted(raw_dir.glob("*.nwb"))
    if not nwb_files:
        print(f"[INFO] No .nwb files found in {raw_dir}")
        return

    for h5_path in nwb_files:
        try:
            target_dir = out_dir if out_dir is not None else h5_path.parent
            stem = h5_path.stem
            out_bin = target_dir / f"{stem}.bin"
            out_meta = target_dir / f"{stem}.json"
            out_locs = target_dir / f"{stem}_channel_locations.npy"

            if not overwrite and out_bin.exists():
                print(f"[SKIP] {out_bin} exists and overwrite=False")
                continue

            with h5py.File(h5_path, "r") as f:
                if dset_path not in f:
                    print(f"[WARN] {h5_path.name}: dataset path '{dset_path}' not found. Skipping.")
                    continue

                d = f[dset_path]
                if d.ndim != 2:
                    print(f"[WARN] {h5_path.name}: dataset at '{dset_path}' must be 2D (time, channels). Got {d.shape}. Skipping.")
                    continue

                k, n = d.shape  # (time, channels)
                n_channels = int(n)
                conv_attr = d.attrs.get("conversion", 1.0)
                try:
                    conv = float(conv_attr)
                except Exception:
                    conv = 1.0

                # Electrode map (optional)
                pos_um = None
                if elec_map_path in f:
                    locs = np.array(f[elec_map_path])
                    if locs.ndim == 1:
                        locs = locs[:, None]
                    if locs.shape[0] != n:
                        print(f"[WARN] {h5_path.name}: electrode_map rows ({locs.shape[0]}) != n channels ({n}). Saving anyway.")
                    pos_um = locs[:, :2] * 1e6

                print(f"[START] {h5_path.name} -> {out_bin.name} | shape: {(k, n)}, dtype: {d.dtype}, conversion: {conv}")

                # Stream to .bin
                with open(out_bin, "wb") as out_f:
                    for i in range(0, k, chunk_samp):
                        sl = slice(i, min(i + chunk_samp, k))
                        buf = d[sl, :]  # (chunk, channels)
                        # apply conversion and cast
                        buf = (buf.astype(np.float32, copy=False) * conv)
                        out_f.write(buf.tobytes())

                # Save locations if available
                if pos_um is not None:
                    np.save(out_locs, pos_um)

                # Save metadata (including fs)
                meta = {
                    "source_nwb": str(h5_path),
                    "out_bin": str(out_bin),
                    "out_channel_locations": str(out_locs) if pos_um is not None else None,
                    "dataset_path": dset_path,
                    "electrode_map_path": elec_map_path if elec_map_path in f else None,
                    "fs_hz": fs,
                    "n_samples": int(k),
                    "n_channels": n_channels,
                    "dtype_written": "float32",
                    "conversion_attr": float(conv),
                }
                with open(out_meta, "w") as jf:
                    json.dump(meta, jf, indent=2)

                print(f"[DONE ] {h5_path.name}: wrote {out_bin.name} ({k} x {n}), meta={out_meta.name}" +
                      (f", locs={out_locs.name}" if pos_um is not None else ""))
                
            rec = read_binary(
                file_paths=out_bin,
                sampling_frequency=fs,
                dtype="float32",
                num_channels=n_channels,
                time_axis=0,
            )

            probe = Probe(ndim=2, si_units='um')
            probe.set_contacts(
                positions=pos_um,                    # (n,2)
                shapes='circle',
                shape_params={'radius': 7}
            )
            probe.set_device_channel_indices(np.arange(n_channels))
            recording = rec.set_probe(probe)
            recording = scale(recording, gain=1e6)
            
            return recording
        except Exception as e:
            print(f"[ERROR] Failed on {h5_path.name}: {e}")
