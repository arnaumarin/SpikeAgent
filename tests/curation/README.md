# Testing Curation Modules

This directory contains test scripts for the curation modules.

## Quick Test

Run the simple test to verify basic functionality:

```bash
# From the repository root
python tests/curation/test_curation_simple.py

# Or from this directory
cd tests/curation
python test_curation_simple.py
```

This will:
- Create a synthetic `sorting_analyzer` with 5 units
- Compute all necessary extensions (waveforms, templates, correlograms, etc.)
- Test creating an image dataframe
- Test rigid curation
- Verify all imports work

## Full Test Suite

Run the comprehensive test suite:

```bash
# From the repository root
python tests/curation/test_curation.py

# Or from this directory
cd tests/curation
python test_curation.py
```

This includes:
1. **Import tests** - Verify all curation modules can be imported
2. **SortingAnalyzer creation** - Create a synthetic analyzer with all extensions
3. **Image dataframe creation** - Test `create_unit_img_df()`
4. **Rigid curation** - Test threshold-based curation
5. **VLM curation structure** - Test VLM curation setup (without API calls)
6. **Guidance functions** - Test the guidance/helper functions

## What is Tested

### SortingAnalyzer Requirements

The curation modules work with a SpikeInterface `SortingAnalyzer` object that must have:

**Required extensions for VLM curation:**
- `waveforms` - For waveform_single and waveform_multi features
- `templates` - For waveform_multi feature
- `correlograms` - For autocorr feature
- `spike_locations` - For spike_locations feature
- `spike_amplitudes` - For amplitude_plot feature

**Optional but recommended:**
- `quality_metrics` - For including quantitative metrics in VLM prompts

### Curation Functions

1. **Rigid Curation** (`get_guidance_on_rigid_curation`)
   - Threshold-based filtering using quality metrics
   - No API calls needed
   - Works with: `sorting_analyzer.get_extension('quality_metrics')`

2. **VLM Curation** (`get_guidance_on_vlm_curation`)
   - Vision-Language Model based classification
   - Requires: API keys, model, and image dataframe
   - Works with: `sorting_analyzer` + `img_df` from `create_unit_img_df()`

3. **VLM Merge Analysis** (`get_guidance_on_vlm_merge_analysis`)
   - For analyzing unit merges
   - Similar requirements to VLM curation

## Example Usage

```python
import sys
sys.path.insert(0, 'src')

import spikeinterface as si
from spikeagent.app.tool.si_custom import create_unit_img_df
from spikeagent.curation.vlm_curation import run_vlm_curation
from spikeagent.app.tool.utils import get_model

# 1. Create or load your sorting_analyzer
# (with all required extensions computed)

# 2. Create image dataframe
img_df = create_unit_img_df(
    sorting_analyzer,
    unit_ids=None,  # All units
    features=["waveform_single", "autocorr", "spike_locations"],
    load_if_exists=False
)

# 3. Run VLM curation (requires API key)
model = get_model("gpt-4o")  # or "claude_3_7_sonnet"
results_df = run_vlm_curation(
    model=model,
    sorting_analyzer=sorting_analyzer,
    img_df=img_df,
    features=["waveform_single", "autocorr"],
    good_ids=[],  # Few-shot examples (optional)
    bad_ids=[],   # Few-shot examples (optional)
    with_metrics=True,
    unit_ids=None  # All units
)

# 4. Apply curation
good_units = results_df.query("final_classification == 'Good'").index.tolist()
curated_analyzer = sorting_analyzer.select_units(good_units)
```

## Notes

- The test scripts use **synthetic data** generated by SpikeInterface
- For real data, you would load your own recording and sorting
- VLM curation requires API keys (set via environment variables or `.env` file)
- The full VLM curation test is skipped in the test suite to avoid API calls
- All curation functions work with a `sorting_analyzer` object, which is correct!

